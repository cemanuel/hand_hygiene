{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This jupyter notebook will be used to prepare for raw data npz files to be fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please organize any new data in the following format that you would like to feed into the model: \\\\br\n",
    "  ---> \\npac_data |\n",
    "                ---> 02 |\n",
    "                         ---> 0 |\n",
    "                                ---> \\d{8}_\\d{6}_\\d{3}.npz\n",
    "                                ---> \\d{8}_\\d{6}_\\d{3}.npz\n",
    "                        ---> 1\n",
    "               ---> 1\n",
    "               \n",
    "In addition, make sure pac_data is in the same directory as this jupyter notebook.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pac_data_directory = \"pac_data\" #Directory of raw numpy images\n",
    "data_directory = \"data\" # Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02', '04', '06', '08', '10', '11', '15', '21', '22', '23', '24', '39', '52', '59', '62', '63', '72']\n"
     ]
    }
   ],
   "source": [
    "potential_sensor_directories = os.listdir(\"pac_data\")\n",
    "sensor_directories = [sensor_dir for sensor_dir in potential_sensor_directories if os.path.isdir(\"pac_data/\" + sensor_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you print 'sensor_directories', you should see all sensor numbers that are listed under the directory of 'pac_data_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sensor_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict = {}\n",
    "sensor_directory_to_list_of_filenames_of_images_labeled_one_dict = {}\n",
    "pattern = r\"\\d{8}_\\d{6}_\\d{3}.npz\"\n",
    "for sensor_dir in sensor_directories:\n",
    "    if os.path.isdir(\"pac_data/\" + sensor_dir + \"/0\"):\n",
    "        potential_filenames_of_images_labeled_with_zero = os.listdir(\"pac_data/\" + sensor_dir + \"/0\")\n",
    "        filenames_of_images_labeled_with_zero = [\"pac_data/\" + sensor_dir + \"/0/\" + f for f in potential_filenames_of_images_labeled_with_zero if os.path.isfile(\"pac_data/\" + sensor_dir + \"/0/\" + f) and re.match(pattern, f)]\n",
    "        sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir] = filenames_of_images_labeled_with_zero\n",
    "    if os.path.isdir(\"pac_data/\" + sensor_dir + \"/1\"):\n",
    "        potential_filenames_of_images_labeled_with_one =  os.listdir(\"pac_data/\" + sensor_dir + \"/1\")\n",
    "        filenames_of_images_labeled_with_one = [\"pac_data/\" + sensor_dir + \"/1/\" + f for f in potential_filenames_of_images_labeled_with_one if os.path.isfile(\"pac_data/\" + sensor_dir + \"/1/\" + f) and re.match(pattern, f)]\n",
    "        sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir] = filenames_of_images_labeled_with_one\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The below cell will be used to split the filenames or store all filenames under one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_for_training_dev_and_testing = True\n",
    "custom_filename = \"custom_filename\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-fb72cddd9f3c>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-fb72cddd9f3c>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    custom_file.write(custom_image_filename + \",\" + \"0\" + )\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def_split_and_create_files_for_training_dev_and_testing()\n",
    "for sensor_dir in sensor_directories:\n",
    "    if os.path.isdir(\"pac_data/\" + sensor_dir + \"/0\"):\n",
    "        if split_for_training_dev_and_testing:\n",
    "            dataset_training_path_sensor = \"data/0/training_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_dev_path_sensor = \"data/0/dev_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_testing_path_sensor = \"data/0/testing_filenames_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_zero_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_zero_labeled = numpy_examples_from_dataset_zero_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir]))]\n",
    "            num_of_examples_in_training_set_zero_labeled = math.ceil(len(numpy_examples_from_dataset_zero_labeled) * 0.70)\n",
    "            num_of_examples_in_dev_set_zero_labeled = math.ceil(math.floor(len(numpy_examples_from_dataset_zero_labeled) * 0.30) * (2.0 / 3.0))\n",
    "            num_of_examples_in_testing_set_zero_labeled = math.floor(math.floor(len(numpy_examples_from_dataset_zero_labeled) * 0.30) * (1.0/3.0))\n",
    "            training_set_zero_labeled = random_ordered_numpy_examples_from_dataset_zero_labeled[:num_of_examples_in_training_set_zero_labeled]\n",
    "            dev_set_zero_labeled = random_ordered_numpy_examples_from_dataset_zero_labeled[num_of_examples_in_training_set_zero_labeled:num_of_examples_in_dev_set_zero_labeled + num_of_examples_in_training_set_zero_labeled]\n",
    "            testing_set_zero_labeled = random_ordered_numpy_examples_from_dataset_zero_labeled[num_of_examples_in_dev_set_zero_labeled + num_of_examples_in_training_set_zero_labeled:]\n",
    "            with gfile.GFile(dataset_training_path_sensor, mode=\"a\") as training_file:\n",
    "                for filename_of_zero_labeled_image_for_training in training_set_zero_labeled:\n",
    "                    training_file.write(filename_of_zero_labeled_image_for_training + \",\" + \"0\" + \"\\n\")\n",
    "            with gfile.GFile(dataset_dev_path_sensor, mode=\"a\") as dev_file:\n",
    "                for filename_of_zero_labeled_image_for_dev in dev_set_zero_labeled:\n",
    "                    dev_file.write(filename_of_zero_labeled_image_for_dev + \",\" + \"0\" + \"\\n\")\n",
    "            with gfile.GFile(dataset_testing_path_sensor, mode=\"a\") as testing_file:\n",
    "                for filename_of_zero_labeled_image_for_testing in testing_set_zero_labeled:\n",
    "                    testing_file.write(filename_of_zero_labeled_image_for_testing + \",\" + \"0\" + \"\\n\")\n",
    "        else:\n",
    "            dataset_custom_path_sensor = \"data/0/\" + custom_filename + \"_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_zero_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_zero_labeled = numpy_examples_from_dataset_zero_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir]))]\n",
    "            with gfile.GFile(dataset_custom_path_sensor, mode=\"a\") as custom_file:\n",
    "                for custom_image_filename in random_ordered_numpy_examples_from_dataset_zero_labeled:\n",
    "                    custom_file.write(custom_image_filename + \",\" + \"0\" + \"\\n\")\n",
    "            \n",
    "    if os.path.isdir(\"pac_data/\" + sensor_dir + \"/1\"):\n",
    "        if split_for_training_dev_and_testing: \n",
    "            dataset_training_path_sensor = \"data/1/training_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_dev_path_sensor = \"data/1/dev_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_testing_path_sensor = \"data/1/testing_filenames_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_one_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_one_labeled = numpy_examples_from_dataset_one_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir]))]\n",
    "            num_of_examples_in_training_set_one_labeled = math.ceil(len(numpy_examples_from_dataset_one_labeled) * 0.70)\n",
    "            num_of_examples_in_dev_set_one_labeled = math.ceil(math.floor(len(numpy_examples_from_dataset_one_labeled) * 0.30) * (2.0 / 3.0))\n",
    "            num_of_examples_in_testing_set_one_labeled = math.floor(math.floor(len(numpy_examples_from_dataset_one_labeled) * 0.30) * (1.0/3.0))\n",
    "            training_set_one_labeled = random_ordered_numpy_examples_from_dataset_one_labeled[:num_of_examples_in_training_set_one_labeled]\n",
    "            dev_set_one_labeled = random_ordered_numpy_examples_from_dataset_one_labeled[num_of_examples_in_training_set_one_labeled:num_of_examples_in_dev_set_one_labeled + num_of_examples_in_training_set_one_labeled]\n",
    "            testing_set_one_labeled = random_ordered_numpy_examples_from_dataset_one_labeled[num_of_examples_in_dev_set_one_labeled + num_of_examples_in_training_set_one_labeled:]\n",
    "            with gfile.GFile(dataset_training_path_sensor, mode=\"a\") as training_file:\n",
    "                for filename_of_one_labeled_image_for_training in training_set_one_labeled:\n",
    "                    training_file.write(filename_of_one_labeled_image_for_training + \",\" + \"1\" +\"\\n\")\n",
    "            with gfile.GFile( dataset_dev_path_sensor, mode=\"a\") as dev_file:\n",
    "                for filename_of_one_labeled_image_for_dev in dev_set_one_labeled:\n",
    "                    dev_file.write(filename_of_one_labeled_image_for_dev + \",\" + \"1\" + \"\\n\")\n",
    "            with gfile.GFile(dataset_testing_path_sensor, mode=\"a\") as testing_file:\n",
    "                for filename_of_one_labeled_image_for_testing in testing_set_one_labeled:\n",
    "                    testing_file.write(filename_of_one_labeled_image_for_testing + \",\" + \"1\" + \"\\n\")\n",
    "        else:\n",
    "            dataset_custom_path_sensor = \"data/1/\" + custom_filename + \"_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_one_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_one_labeled = numpy_examples_from_dataset_one_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir]))]\n",
    "            with gfile.GFile(dataset_custom_path_sensor, mode=\"a\") as custom_file:\n",
    "                for custom_image_filename in random_ordered_numpy_examples_from_dataset_one_labeled:\n",
    "                    custom_file.write(custom_image_filename + \",\" + \"1\" + \"\\n\")\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
