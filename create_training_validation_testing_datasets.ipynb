{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This jupyter notebook will be used to prepare for raw data npz files to be fed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pac_data_directory   \n",
    "│\n",
    "└───02\n",
    "│   │\n",
    "│   └───0   \n",
    "│   │   │   20160930_082811_796.npz\n",
    "│   │   │   20160930_082811_996.npz\n",
    "│   │\n",
    "│   │\n",
    "│   └───1\n",
    "│       │   20160930_084735_699.npz\n",
    "│       │   20160930_084735_931.npz\n",
    "   \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_directory\n",
    "│\n",
    "└───0   \n",
    "│   │ training_filenames_02.txt\n",
    "│   │ custom_filenames_02.txt\n",
    "│   │\n",
    "│ \n",
    "└───1\n",
    "│   │ training_filenames_02.txt\n",
    "│   │ custom_filenames_02.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pac_data_directory = \"pac_data\" #Directory of raw numpy images\n",
    "data_directory = \"data_2\" # Directory that contain two subdirectories, '0' and '1'. Within\n",
    "                          # each of these subdirectories, will be stored files containing filenames / paths that point\n",
    "                          # to the raw npz images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "potential_sensor_directories = os.listdir(pac_data_directory)\n",
    "sensor_directories = [sensor_dir for sensor_dir in potential_sensor_directories if os.path.isdir(pac_data_directory + \"/\" + sensor_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you print 'sensor_directories', you should see all sensor numbers that are listed under the directory of 'pac_data_directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02', '04', '06', '08', '10', '11', '15', '21', '22', '23', '24', '39', '52', '59', '62', '63', '72']\n"
     ]
    }
   ],
   "source": [
    "print(sensor_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict = {}\n",
    "sensor_directory_to_list_of_filenames_of_images_labeled_one_dict = {}\n",
    "pattern = r\"\\d{8}_\\d{6}_\\d{3}.npz\"\n",
    "for sensor_dir in sensor_directories:\n",
    "    if os.path.isdir(pac_data_directory + \"/\" + sensor_dir + \"/0\"):\n",
    "        potential_filenames_of_images_labeled_with_zero = os.listdir(pac_data_directory + \"/\" + sensor_dir + \"/0\")\n",
    "        filenames_of_images_labeled_with_zero = [pac_data_directory + \"/\" + sensor_dir + \"/0/\" + f for f in potential_filenames_of_images_labeled_with_zero if os.path.isfile(pac_data_directory + \"/\" + sensor_dir + \"/0/\" + f) and re.match(pattern, f)]\n",
    "        sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir] = filenames_of_images_labeled_with_zero\n",
    "    if os.path.isdir(pac_data_directory + \"/\" + sensor_dir + \"/1\"):\n",
    "        potential_filenames_of_images_labeled_with_one =  os.listdir(pac_data_directory + \"/\" + sensor_dir + \"/1\")\n",
    "        filenames_of_images_labeled_with_one = [pac_data_directory + \"/\" + sensor_dir + \"/1/\" + f for f in potential_filenames_of_images_labeled_with_one if os.path.isfile(pac_data_directory + \"/\" + sensor_dir + \"/1/\" + f) and re.match(pattern, f)]\n",
    "        sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir] = filenames_of_images_labeled_with_one\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The below cell will be used to split the filenames or store all filenames under one file, separated by classtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_for_training_dev_and_testing = True\n",
    "custom_filename = \"custom_filename\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sensor_dir in sensor_directories:\n",
    "    if os.path.isdir(pac_data_directory + \"/\" + sensor_dir + \"/0\"):\n",
    "        if split_for_training_dev_and_testing:\n",
    "            dataset_training_path_sensor = data_directory + \"/0/training_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_dev_path_sensor = data_directory + \"/0/dev_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_testing_path_sensor = data_directory  + \"/0/testing_filenames_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_zero_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_zero_labeled = numpy_examples_from_dataset_zero_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir]))]\n",
    "            num_of_examples_in_training_set_zero_labeled = math.ceil(len(numpy_examples_from_dataset_zero_labeled) * 0.70)\n",
    "            num_of_examples_in_dev_set_zero_labeled = math.ceil(math.floor(len(numpy_examples_from_dataset_zero_labeled) * 0.30) * (2.0 / 3.0))\n",
    "            num_of_examples_in_testing_set_zero_labeled = math.floor(math.floor(len(numpy_examples_from_dataset_zero_labeled) * 0.30) * (1.0/3.0))\n",
    "            training_set_zero_labeled = random_ordered_numpy_examples_from_dataset_zero_labeled[:num_of_examples_in_training_set_zero_labeled]\n",
    "            dev_set_zero_labeled = random_ordered_numpy_examples_from_dataset_zero_labeled[num_of_examples_in_training_set_zero_labeled:num_of_examples_in_dev_set_zero_labeled + num_of_examples_in_training_set_zero_labeled]\n",
    "            testing_set_zero_labeled = random_ordered_numpy_examples_from_dataset_zero_labeled[num_of_examples_in_dev_set_zero_labeled + num_of_examples_in_training_set_zero_labeled:]\n",
    "            with gfile.GFile(dataset_training_path_sensor, mode=\"a\") as training_file:\n",
    "                for filename_of_zero_labeled_image_for_training in training_set_zero_labeled:\n",
    "                    training_file.write(filename_of_zero_labeled_image_for_training + \",\" + \"0\" + \"\\n\")\n",
    "            with gfile.GFile(dataset_dev_path_sensor, mode=\"a\") as dev_file:\n",
    "                for filename_of_zero_labeled_image_for_dev in dev_set_zero_labeled:\n",
    "                    dev_file.write(filename_of_zero_labeled_image_for_dev + \",\" + \"0\" + \"\\n\")\n",
    "            with gfile.GFile(dataset_testing_path_sensor, mode=\"a\") as testing_file:\n",
    "                for filename_of_zero_labeled_image_for_testing in testing_set_zero_labeled:\n",
    "                    testing_file.write(filename_of_zero_labeled_image_for_testing + \",\" + \"0\" + \"\\n\")\n",
    "        else:\n",
    "            dataset_custom_path_sensor = data_directory + \"/0/\" + custom_filename + \"_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_zero_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_zero_labeled = numpy_examples_from_dataset_zero_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_zero_dict[sensor_dir]))]\n",
    "            with gfile.GFile(dataset_custom_path_sensor, mode=\"a\") as custom_file:\n",
    "                for custom_image_filename in random_ordered_numpy_examples_from_dataset_zero_labeled:\n",
    "                    custom_file.write(custom_image_filename + \",\" + \"0\" + \"\\n\")\n",
    "            \n",
    "    if os.path.isdir(pac_data_directory + \"/\" + sensor_dir + \"/1\"):\n",
    "        if split_for_training_dev_and_testing: \n",
    "            dataset_training_path_sensor = data_directory + \"/1/training_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_dev_path_sensor = data_directory + \"/1/dev_filenames_\" + sensor_dir + \".txt\"\n",
    "            dataset_testing_path_sensor = data_directory + \"/1/testing_filenames_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_one_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_one_labeled = numpy_examples_from_dataset_one_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir]))]\n",
    "            num_of_examples_in_training_set_one_labeled = math.ceil(len(numpy_examples_from_dataset_one_labeled) * 0.70)\n",
    "            num_of_examples_in_dev_set_one_labeled = math.ceil(math.floor(len(numpy_examples_from_dataset_one_labeled) * 0.30) * (2.0 / 3.0))\n",
    "            num_of_examples_in_testing_set_one_labeled = math.floor(math.floor(len(numpy_examples_from_dataset_one_labeled) * 0.30) * (1.0/3.0))\n",
    "            training_set_one_labeled = random_ordered_numpy_examples_from_dataset_one_labeled[:num_of_examples_in_training_set_one_labeled]\n",
    "            dev_set_one_labeled = random_ordered_numpy_examples_from_dataset_one_labeled[num_of_examples_in_training_set_one_labeled:num_of_examples_in_dev_set_one_labeled + num_of_examples_in_training_set_one_labeled]\n",
    "            testing_set_one_labeled = random_ordered_numpy_examples_from_dataset_one_labeled[num_of_examples_in_dev_set_one_labeled + num_of_examples_in_training_set_one_labeled:]\n",
    "            with gfile.GFile(dataset_training_path_sensor, mode=\"a\") as training_file:\n",
    "                for filename_of_one_labeled_image_for_training in training_set_one_labeled:\n",
    "                    training_file.write(filename_of_one_labeled_image_for_training + \",\" + \"1\" +\"\\n\")\n",
    "            with gfile.GFile( dataset_dev_path_sensor, mode=\"a\") as dev_file:\n",
    "                for filename_of_one_labeled_image_for_dev in dev_set_one_labeled:\n",
    "                    dev_file.write(filename_of_one_labeled_image_for_dev + \",\" + \"1\" + \"\\n\")\n",
    "            with gfile.GFile(dataset_testing_path_sensor, mode=\"a\") as testing_file:\n",
    "                for filename_of_one_labeled_image_for_testing in testing_set_one_labeled:\n",
    "                    testing_file.write(filename_of_one_labeled_image_for_testing + \",\" + \"1\" + \"\\n\")\n",
    "        else:\n",
    "            dataset_custom_path_sensor = data_directory + \"/1/\" + custom_filename + \"_\" + sensor_dir + \".txt\"\n",
    "            numpy_examples_from_dataset_one_labeled = np.array(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir])\n",
    "            random_ordered_numpy_examples_from_dataset_one_labeled = numpy_examples_from_dataset_one_labeled[np.random.permutation(len(sensor_directory_to_list_of_filenames_of_images_labeled_one_dict[sensor_dir]))]\n",
    "            with gfile.GFile(dataset_custom_path_sensor, mode=\"a\") as custom_file:\n",
    "                for custom_image_filename in random_ordered_numpy_examples_from_dataset_one_labeled:\n",
    "                    custom_file.write(custom_image_filename + \",\" + \"1\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
